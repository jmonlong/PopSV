% Generated by roxygen2 (4.1.0): do not edit by hand
% Please edit documentation in R/chunk.bin.R
\name{chunk.bin}
\alias{chunk.bin}
\title{Split the cbins in chunks}
\usage{
chunk.bin(bins.df, bg.chunk.size = 1e+05, sm.chunk.size = 1000,
  large.chr.chunks = FALSE)
}
\arguments{
\item{bins.df}{a data.frame with the bins definition (one row per bin). E.g. created by
'fragment.genome.hp19'.}

\item{bg.chunk.size}{the number of bins in a big chunk.}

\item{sm.chunk.size}{the number of bins in a small chunk.}

\item{large.chr.chunks}{should the big chunks be made of just some large genomic sub-regions ? Default is false. It is faster than using random bins, hence recommended when dealing with a large number of bins (e.g. > 5e5).}
}
\value{
an updated data.frame with 'sm.chunk', 'bg.chunk' and 'bin' with the small chunk
ID, big chunk ID and bin definition.
}
\description{
Split the bins into big and small chunks. A big chunk represents all the bins used to
normalize bins of this chunk. Small chunk represents the bins to analyze by one job
on the cluster. While the size of the small chunks is not important and can be adjusted
to fit the cluster, the big chunk size will impact on the efficiency of the normalization
(the bigger the better).
}
\author{
Jean Monlong
}

